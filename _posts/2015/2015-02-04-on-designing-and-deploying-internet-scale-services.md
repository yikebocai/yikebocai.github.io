---
layout: post
title: 可扩展互联网服务的设计和部署【译】
categories: tech
tags: 
- architecture
---

> 这篇译文源自当时还在微软`Windows Live Services Platform`部门的[James Hamilton](http://www.mvdirona.com/jrh/work/)的经典论文 [On Designing and Deploying Internet-Scale Services](https://www.usenix.org/legacy/event/lisa07/tech/full_papers/hamilton/hamilton_html/)，他现在是Amazon Web Services团队的成员之一，读了一遍感觉还有很多不够清晰，遂决定把它翻译成中文，以便更深入的了解。

## 概述

系统和管理员的比例通常作为一个大概指标来衡量高扩展服务的管理成本。对于规划较小很少有自动化的服务这个比率可能会低至`2：1`，但在领先并高度自动化的服务，这个比率可能高达`2500：1`。在微软的服务里，`Autopilot`常被称作Windows Live搜索团队成就高系统管理员比率后面的魔法。既然自动化管理如此重要，最重要的因素其实是服务自身。是服务高效到自动化？什么是我们通常称作的运维友好？运维友好的服务要求很少的人工介入，并且大部分复杂异常的检测和恢复不需要管理的介入。本论文总结了来自MSN和Windows Live在大规模服务多年的最佳实践。

## 介绍

本篇论文总结了设计和部署运维友好的服务的一系列最佳实践。这是一个快速变化的主题领域，因此，最佳实践的任何列表都可能随着时间而变化。我们的目标是帮助那些：

* 快速开发运维友好的服务，并且
* 避免因此非运维友好服务导致的凌晨被电话吵醒以及和不高兴的客户开会

该工作基于我们过于20年在高扩展数据中心软件系统和可扩展互联网服务的经验，大多数来自近期领导Exchange Hosted Services团队（当时，一个中等规模的服务有近700服务器和220万以上的用户）。我们也吸收了来自Windows Live Search，Windows Live Mail，Exchange Hosted Services，Live Communications Server，Windows Live Address Book Clearing House（ABCH），MSN Spaces，Xbox Live，Rackable Systems Engineering Team，和Messenger Operations团队以及Microseft Global Fuundation Services Operations团队的经验。好几个上述的服务的用户量已经增长到超过2.5亿。本论文也严重依赖Berkeley在Recovery Oriented Computing以及Standford在Crash-Only Software方面所做的工作。

`Bill Hoffman`对本论文贡献了很多最佳实践，最下面这三个信条最值得放在前面来说：

* **期待失败（Expect failures）**。一个组件可能在任何时间都会崩溃或都停止。依赖的组件也可能在任何时间会失败或被停止。这可能是网络失败，磁盘空间不足。优雅地处理所有可能的失败。
* **保持事情简单（Keep things simple）**。复杂产生问题。简单的事情更容易做对。避免不必要的依赖。安装要简单。一个服务器失败不要影响数据中心的其它机器。
* **自动化一切事情（Automate Everything）**。人会制造错误。人需要休息。人会忘记事情。自动化过程是可测的，可固化的，因此会更可靠。如果可能尽量自动化。

这三个信条是下面讨论的主题。

## 建议

本文由十个部分组成，每一部分涵盖设计和部署运维友好的服务的一个方面。包括：整体服务设计；面向自动化和配置的设计；依赖管理；发布周期和测试；硬件选型和标准化；运维和容易规划；审核，监控和报警；优雅降级和准入控制；客户和出版沟通计划；客户自助服务。

### 整体应用设计（Overall Application Design）

我们一直相信80%的运维问题源自设计和部署，因此整体服务设计是本文中最大和最重要的部分。当系统失败时，一个自然的倾向是首先去看运维状况，因为它是问题实际发生的地方。大多数运维问题，既然源自设计和部署，那么最好就是这里解决它们。

贯穿下面章节的一个共识是：严格区分开发，测试和运维在服务的世界里不是最有效的方式。我们看到很多低成本管理服务的趋势是和开发、测试、运维团队紧密工作密切相关。

除了这里讨论的最佳服务设计实践之外，随后的章节，“面向自动化和配置的设计”，在服务设计上也在重要的影响。高效的自动化管理和配置通常仅在一个约束的服务模型里才能达成。这里有一个始终重复的主题：简单是高效运维的核心。在硬件选择，服务设计，和部署模型上的关联约束是减少管理成本和提升服务可用性的极大驱动力。

一些运维友好的基本准则在整体服务设计上有最大的影响：

* **面向失败的设计（Desing for failure）**。这是在开发由许多相互协作的组件组成的大型服务系统时的最核心概念。这些组件会出问题并且会不断地出问题。这些组件也不会总是独立地协作和失败。当服务扩展到1万台服务器和5万块硬盘以上时，每天都会发生多次问题。如果一个硬件故障需要立即有人工介入，这个服务就无法成低配的扩展和可靠。整个服务必须具备没有人工介入也能处理故障的能力。故障恢复必须是一个简单的路径，并且该路径必须经过不断的测试。Standford的`Armando Fox`曾经对测试故障最佳的办法是不要正常关闭服务有过争论。就要通过暴力让它失败。这个听起来有点违反直觉，但如果一个故障路径没有不断的被使用，当需要的时候它很可能无法工作。

* **冗余和故障恢复（Redundancy and fault recovery）**。大型主机模式是买一个非常巨大，非常昂贵的服务器。主机有冗余的电源供应，热切换的CPU，和在一个单一双路的系统内能够提供可观的I/O吞吐量的外部总线架构。这些系统显而易见的问题是它们的费用。并且即使所有成本高昂的工程师都在，它们也无法足够可靠。为了获得5个9的可靠性，冗余是必须的。即使在一个单系统部署上获得4个9的可靠性也很困难。这个概念在工业界相当容易理解，但依然经常看到有服务构建在脆弱的、非冗余的数据层上面。设计一个在任何时间任何系统都可能崩溃（或者服务当掉）但仍然能达到服务等级协议(SLA)的服务需要非常小心的工程师。能够完全接受这个设计准则的ACID测试如下：运维团队能够在任意时间没有先降低工作负载的情况下下掉服务中的任何一台服务器吗？如果是，这就是同步冗余（没有数据丢失），故障检测，和自动故障转移。作为一个设计办法，我们建议一个通常使用的办法来发现和纠正潜在的服务安全问题：安全威胁建模。在安全威胁建模中，我们考虑每一个可能的安全威胁，对每一个给给予足够的减缓。同样的办法能被用作故障恢复设计。由此文档化所有可想到的组件故障模式和混合情况。对于每一个故障，确保服务能继续运行，并且没有不可接受的服务质量损失，或者确定这个故障风险对特定的服务是可接受的（比如，在一个非常空间冗余服务中丢失所有数据）。非常反常的组合也许不太可能被充分地查明，确保系统能通过它们正常运行是不经济的。但当做此决定时要小心。当运行上千台服务器每天有上百万的机会可能产生组件故障时我们惊讶于非正常事件是多频繁的发生。罕见的组合会变得很平常。

* **廉价硬件（Commodity hardware slice）**。所有的服务组件都会对应到廉价硬件切片上。比如，轻存储的服务器会是全双工，2~4核的系统，一个启动盘，$1000~$2500范围内，重存储的服务器通常会用16到24个磁盘。最重要的观察如下：
  - 大规模的商业服务器集群比它们替换掉的小规模的大型服务器便宜多了，
  - 服务器性能会比I/O性能的增长快很多，为特定数量的磁盘使用一个更小但更平衡的系统，
  - 电力消耗会随着服务线性增长但和时钟频率呈立方，使用最高性能的服务器运行会更贵，并且
  - 一个小型服务器当机时对整体服务处理能力的影响比例也更小

* **单一版本软件（Single-version software）**。两个因素导致一些服务比大多数打包好的产品开发成本更低并且进行更快：
  - 软件只需要单一内部部署，并且
  - 对企业级产品来说不需要支持前一个版本十年。
单一版本软件相对来说更容易和一个客户服务集成，特别是免费提供的。但当销售基于订金的服务给非客户时它也是同等重要。当企业部署新版本时（特别地慢）他们于他们的软件提供商有显著的影响和完全的控制权。既然那么多的软件版本需要支持，这会提升它们的运营成本和支持成本。最经济的服务是不要给客户版本的控制权，仅支持一个版本。维持单一版本软件线要求：
  - 观注非产生重要用户体验改变的发布，并且
  - 乐于允许需要这个控制级别的客户要么内部托管或者切换到愿意提供对人员敏感的多版本支持的应用服务提供商

* **多租户（Multi-tenancy）**。多租户是指所有公司或终端用户的服务托管在同一个服务中不要做物理隔离，而单租户是在一个独立的集群中做用户分组的隔离。对多租户的争论和对单版本支持几乎是一样的，并且是基于提供基础的、构建在自动化和大规模可扩展的低成本服务。

总结一下，我们在上面提到的基本的设计准则和考虑点如下：

* 面向失败的设计，
* 实现冗余和故障恢复，
* 基本商业硬件，
* 支持单版本软件，
* 支持多租户

我们正在约束服务设计和运维模型以便最大化我们自动化的能力并减少整体的服务成本。我们和那此应用服务提供商或IT外包有明显的区别。那商业模式趋向于用更多的人以及更多的意愿运行复杂的、客户定制的配置。

更加具体的运维友好的服务设计最佳实践如下：

* **快速服务健康检查（Quick service health check）**。这是一个构建验证测试的服务版本。它是一个能够在开发者的系统中快速运行的小测试，以及保证该服务不会被任何重要步骤打断。并非所有边界用例都会被测到，但是一但健康检查通过，代码就可以入库。
* **在完整的环境中开发（Develop in the full environment）**。开发应该对他们的组件做单元测试，但是也应该对所有涉及组件变更的服务做测试。要高效地完成该目标需要做单一服务器部署（见2.4）,并且执行最佳实践，快速服务健康检查。
* **对下层零信任（Zero trust of underlying components）**。假设下层组件会失败并且确保这些组件能够恢复和继续提供服务。恢复技术和具体服务相关，但能用的技术如下：
  - 在只读模式下继续操作缓存的数据，并且
  - 当服务正在访问失败组件的冗余备份这一小段时间内继续给所有用户提供服务但是很小一部分受影响的用户除外。
* **不要在多个组件里构建同一功能（Do not build the same functionality in multiple components）**。预见未来的相互作用是困难的，如果代码冗余悄然发生，不得不在系统的多个部分进行修复。服务成长和进化很快。如果不关心，代码会很快恶化。
* **一个节点或集群之间不要相互影响（One pod or cluster should not affect another pod or cluster）**。大多数服务由多个节点或者一起工作的子集群系统组成，这里每一个节点能够相对独立地运行。每一个节点应该接受100%的独立并且不要有内部节点关联的失败。即使有冗余的全球服务也是一个失败的中点。有时他们难以避免，但是尽量把一个集群中需要的所有东西都放在集群外面。
* **允许（但很少）紧急人工介入（Allow （rare）emergency human intervention）**。通常的桥段是在发生灾难性的事件或其它紧急情况时迁移用户的数据。系统设计时永远不需要人工参与，但要理解在组合的失败情况下或者未预料到的失败情况需要人工介入也是有可能出现的。这些事件在这些状况下出现和操作错误是导致灾难性数据丢失的源头。一个运维工程师在压力下于凌晨2点工作将会制造错误。设计系统的第一原则是在大多数情况不需要人工介入，但是如果他们需要介入，能够有恢复计划地做运维工作。相对于把这些固化成几个步骤，把他们写成脚本并在生产环境中测试它们并确保他们能正常工作会更好。不在生产环境测试就不会正常工作，因此运维团队需要定期使用这些工具进行消防演练。如果服务可用性风险极度高危，那么无效的投资已在设计、开发和测试这些工具时埋下种子。
* **保持事情简单和健壮（Keep things simple and robust）**。复杂的算法和组件相互影响会增加了调试、部署等的难度。简单和足够直接在高扩展的服务中总是更好-在复杂的优化开始之前相互影响的大量问题已让人望而却步。我们总的原则是带来重大提升的优化是值得考虑的，但部分或者甚至只有很小的收益是不值得的。
* **在所有层级进行强制准入控制（Enforce admission control at all levels）**。任何好的系统都会在门口设计准入控制。这个是根据久经考验的原则：不要让已经过载的系统接收更多的工作比继续接收工作并开始崩溃要好。一些节流或准入控制在进入服务时是很常见的，但是应该在所有主要组件的边界都做准入控制。尽管整体服务可以接受的负载水平继续运行，但是工作负载的改变最终还是会导致子组件的过载。可以参考2.8紧急开关这节，在过载时做优雅降级作为一种解决办法。总是原则是优雅降级优于直接失败，在给所有用户提供统一的糟糕服务前阻止进入服务。
* **分区服务（Partitions the service）**。分区应该是无限可调整和细粒度的，并且不会被任何真实世界的实体（人，组织...）所限制。如果按公司做分区，那么一家大公司就会超过很多单一个体的数量。如果按名字前缀做分区，比如所有以P开头的，就无法集中在一台服务器上。我们推荐在中间层使用一个查询表来做细粒度的实体映射，典型的像用户到他们的数据被管理的系统。这些细粒度的分区可以自由地在服务器之间进行移动。
* **分析吞吐量和延迟（Analyze througput and latency）**。对用户使用的核心服务进行吞吐量和延迟分析能够理解它的影响。做些其它操作，比如常规的数据库维护，操作配置（新用户增加，用户迁移），服务调试等。靠周期性的管理任何可以帮助捕获异常。对每一个服务来说，都应该有一个为容量规划而出现的指标，比如每一个系统的每一秒的用户请求数，每一个系统的在线用户并发数，或者映射工作负载到资源需求的一些指标。
* **把运维工具做为服务的一部分（Treat operations utilities as part of the service）**。开发、测试、程序管理和运维的工具都应该由开发来做代码审核，提交到主代码库，并追踪时间计划以及做同样的测试。通常这些工具是应付紧急任务还几乎没有被测试过。
* **了解访问模式（Understand access patterns）**。当准备新功能时，总是考虑他们要给后端存储增加什么样的负载。服务模型和服务开发人员总是变得远离存储，他们会忘记看放在下层数据库的负载。一个最佳实践是把它放在说明文档中，就像那章“这个功能会对剩余的基础设施有什么影响？”，然后当这个功能可用时评估和校验它的负载。
* **一切版本化（Version everything）**。期望运行在一个混合版本的环境中。目标是运行单一版本的软件，但是在首次发布和生产测试时会存在多个版本。所有组件的版本n和n+1需要和平共处。
* **从上一次发布中保持单元/功能测试（Keep the unit/funcational tests from the previous release）**。这些测试是验证上一个版本功能没有出现问题的一种非常好的方法。我们建议更进一步，不断地在生产环境运行服务验证测试（详见下面）。
* **避免单点故障（Avoid single points of failure）**。单点故障会导致服务或部分服务不可用。倾向于无状态的实现。不要把请求或客户端和具体的服务器绑死。代替的是，在一组能处理这样负载的服务器上使用负载匀衡。静态哈希或者任何静态工作分配经过一段时间后都可能会遇到数据或查询倾斜的问题。当同一等级的服务器可以互换时水平扩展是很容易的。数据库经常存在单点故障并且数据库的扩展仍然是设计可扩展的互联网服务中最难的点。使用细粒度的分区并且不支持跨分区操作的良好设计能跨许多数据库服务器高效扩展。

### 自动化管理和配置（Automatic Management and Provisioning）

很多用来作故障预警的服务在恢复时需要人工介入。这种模式的问题是24*7的运维人员是很昂贵的。更重要的是，如果运维工程师在压力下做决策，大概20%的概率会导致出问题。这种模式既昂贵又容易出错，并且会减少整体服务的可靠性。

设计自动化，无论如何，要需要重要的服务模型约束。比如，今天一些大型服务依赖数据库到备份服务器的异步复制功能。在主机不能服务时切换到备机时，会在做异步复制时丢掉一些客户数据。尽管如此，如果不切换到备机会导致服务当机影响那此数据存储在出故障的数据库服务器上的客户。在这个案例中，做自动化故障切换是比较困难的，因为它依赖人工判断和当机时间内丢失数据量的精确评估。一个自动化的系统补偿了同步复制的延迟和吞吐量成本。并且，这样做了，故障变成一个简单决策：如果主机当了，自动路由到备机。这种办法对自动化来说容易接受的多并且更少出错。

在设计和部署之后一个服务的自动化管理可能非常困难。成本的自动化需要简单和清晰，容易做出操作决策。这个反过来依赖一个非常小心的服务设计，有必要时，牺牲一些延迟和吞吐量以更容易做自动化。这个权衡经常比较难以制定，但是在高扩展服务中可以节省大量管理成本。事实上，在大部分是人工和大部分自动化服务之间的差距主要是在人员成本上的巨大差异。

自动化设计的最佳实践包括：

* **能重复并冗余（Be restartable and redundant）**。所有的操作都必须能够重复执行并且所有的持久化状态必须冗余存储。
* **支持跨地区分布（Support geo-distribution）**。所有高扩展的服务都应该支持跨数据中心的运行。为了公正起见，我们在这里描述的自动化和大部分提升效率的东西都是不涉及到跨地区分布的。但是缺少跨多数据中心的支持，部署会戏剧性地提升运维成本。没有跨地区分布，就很难利用一个数据中心的空闲能力去减轻另一个数据中心服务的负载。跨地区分布的缺失不利于约束运维成本的提升。
* **自动化分发和安装（Automatic provisioning and installation）**。分发和安装，如果手工来做，成本很高，会有太多问题，并且微小的配置差异会慢慢地放大导致定位问题会难的多。
* **配置和代码一体（Configuration and code as a unit）**。确保：
  - 部署团队要把代码和配置作为一体来传递，
  - 它被测试以和运维完全一样的方式部署，并且
  - 运维也是把它们做作为一体来部署
把配置和代码作为一体对待并且只能同时改变它们的服务通常更可靠。如果在生产环境一个配置必须被变更，确保所有的变更都会生成审计日志，清楚地记录变更了什么内容，何时变更，是谁变更，哪些服务器受到了影响。不断地扫描所有的服务器确保它们当前的状态是符合预期的状态。这能帮助捕获安装和配置问题，尽早地检测到服务器的错误配置，并且发现没有审计的服务器配置变更。
* **管理服务器角色或特性甚于服务器本身（Manage server roles or personalities rather than servers）**。每一个系统角色或特性都应该支持按需部署在或多或少的服务器上。
* **多系统问题很正常（Multi-system failures are common）**。预计很多主机在同一时间出现问题（电力，网络交换，和首次发布）。不幸的是，有状态的服务不得不知道拓扑结构。实际的生活中总是有相关联的问题存在。
* **服务级别恢复（Recover at the service level）**。在执行上下文都可用的服务级别处理异常和修正错误比在低层给的软件层面更好。比如，做服务的冗余优于依赖低层软件的恢复。
* **永远不要依靠本地存储做不恢复的信息（Never rely on local storage for non-recoverable information）**。总是对所有的非短暂的服务状态进行复制。
* **保持部署简单（Keep deployment simple）**。能够给予最大限度的部署灵活性的文件拷贝是理想的。最小化外部依赖。避免复杂的安装脚本。任何阻碍在同一个服务器上运行不同组件或者同一组件的不同版本行为都应该避免。
* **有规律地让服务失败（Fail services regularly）**。当掉数据中心，当掉机柜，把服务器断电。常规的有控制的当机都会充分暴露服务、系统和网络的脆弱性。这此在生产环境中的异常测试仍不能确保在出问题时服务仍能继续运行。并且，没有生产测试，在真正使用时无法正常恢复。

### 依赖管理（Dependency Management）


