---
layout: post
title: 最近做的一些系统改造
categories: tech
tags: 
- ha
---

最近系统出了几次大的问题，逼迫我们不得不暂停新功能的开发，把系统改进提前进行，经过几次改进后，系统具备了基本的线性扩展和高可用性，后面压力增加个几倍也不用太担心了。

## 线性扩展
系统原来核心的应用都具备了线性扩展，根据调用量可以随时增加新的机器分担压力，但是存储是个绝对的瓶颈，只有一台MySQL，并且IO性能非常低，压力一大数据写入就会堆积，这个问题不彻底解决，根本无法支撑业务的高速发展。因此从两个月前就开始考虑如果存储`velocity`和`activity`这些大数据，使用Mysql也不是不可以，但需要自己做分库分表非常麻烦，而我们又缺少像阿里`TDDL`这样成熟的数据中间件产品，因此并没有过多地把精力放在MySQL上面，而是将眼光投到业界流行的NoSQL方案。业界流行的MongoDB、Hbase在国内都有大量使用，并且在阿里时也是用的Hbase，相对来说还熟悉一点，但相对复杂的部署和较高的成本（至少需要5台服务器），对我们这样的初创企业来说，实在有点难以承受，最后选择了Cassandra，它是P2P的结构，不存在中心节点，使用两台机器就可以搭建一个基本的高可用数据系统，并且以后可以根据需要随时增加新的节点。

从开始阅读Cassandra官方文档到功能测试到性能测试一直到线上功能改造和切换，花了两个多月的时间，中间也经历各种问题和方案的几次变动，终于顺利地从MySQL切换过去，解决了数据存储的大问题，后面再也不用担心数据越来越多没法存储的问题了。

大数据迁移到Cassandra之后，MySQL只用存储一些基本的配置和规则数据，以及统计报表的数据，即使不做分库分表也完全可以满足一两年之内的需要。

## 高可用性
高可用性也是构建SAAS服务基本要求，没有一个稳定的系统，即使花很大力气把客户请进来了，人家还是会很快跑掉的，因此也花了很大力气来解决系统中的单点问题。

首先是使用`Keepalived`对反向代理服务器做了热备，保证在主机当掉后可以自动切换到备机上面。这个其实在最开始系统正式上线时已经部署好了，但后来为了能让备机可以访问外网，配置了一个代理网关，导致中间做切换时发现切换不了，查了好久才发现是这个问题，改正后做一次演练可以正常切换。

其次是缓存服务器，原来也是只有一个节点，最近出过两次问题一次是有人不小心把它重启了，结果缓存中的数据全丢了，请求的压力一下子就全部打到了MySQL数据库上了，而那时MySQL还没有升级，性能非常差导致调用大量超时。还有一次时MySQL性能突然急剧下降，大家都在手忙脚乱地处理这个问题时，Memcached所在的VM也挂了，屋漏偏逢连阴雨，当时如坠冰窟。好在后面发现只是VM挂起来了，数据并没有丢失。单点的故障短短时间内发生了两次，逼着我们不得不尽快解决这个问题。当时考虑了两种方案，一种是增加一个Memcached节点，使用一致性Hash组成一个集群，保证即使当掉一台也不至于全军覆灭。另外一个方案是使用Redis，利用它的主备功能保证主机当掉后自动切换到备机，数据不会丢失。但通过几天的研究和测试发现，Redis无法很好地支持集群，如果以后需要更多的缓存空间，不能方便地扩展，它的集群方案还处于测试阶段，并且每个节点都要做主备成本过高，还要考虑迁移的成本。而使用Memcached，代码不需要做任何改动，只需要在Memcached的主机列表中增加新的节点配置就行了，唯一不够完美的就是当掉一个节点数据会丢失，但随着节点的增多，当机一个节点的影响是越来越小，完全可以接受，因此决定使用这种方案。

MySQL原来的单点问题也是困扰了我们很久，但招了两个DBA都被放了鸽子，现在的人职业素质实在不敢恭维。没有专业的DBA，线上的MySQL我们也不敢随便动，直到出现了严重的性能问题，不得不找到原来阿里的老同事现在的沃趣的MySQL数据库专家李春，详细地讨论了数据库改进的方案后，才逐步完成了MySQL的主从复制方案，双Master自动切换的方案还有待DBA来了之后再做完善。主从复制完成之后，对数据库单点的担心才稍稍平复一点。

Cassandra本身已是集群结构，已经不存在单点问题，任何一个节点挂掉都不影响线上的使用和数据的完整性。

## 性能优化

原来每次发布时，应用重启都会导致性能的急剧抖动，主要原因时发布时没有把重启的服务器从反向代理服务的负载匀衡列表中踢掉，应用容器一初始化成功，请求就会分配进来，但此时应用本身还有很多东西没有初始化，请求会被阻塞，导致刚开始时响应性能很差。原来使用的是Apache做反向代理，没有方便的接口可以通过脚本控制，而阿里有个人为Nginx写了这样一个插件，可以通过url来动态修改upstream实现我们这个要求，随之就从Apache迁移到了Nginx，每次执行发布脚本时，先将要发布的服务器从upstream列表中摘掉，等发布成本再将它加进去，切换之后再进行发布基本已没有任何影响了。

另外系统原来的设计是请求处理完毕后，将原始请求数据和处理结果放入本地队列，然后再慢慢写入MySQL和Memcached，这个设计本向没有太大问题，同步处理请求异步将请求和结果数据存储起来以备下次计算使用，但是有一个致命的问题是写入velocity数据到MySQL和Memcached是在同一个线程中处理的，一但MySQL写入速度变慢，也会导致Memcached写入变慢，这会严重影响计算的准确性，因为velocity计算会先从Memcached中读取数据。最严重时队列会堆积好几万的数据，大量velocity读取无法命中Memcached要读取MySQL，导致MySQL性能进一步下降，Memcached写入的速度更加慢，陷入恶性循环。本来在MySQL性能问题爆发前就开始做此点改进了，结果还没有完成，第二天就爆发了，看来真应了那句话，你觉得有问题的地方迟早会爆发，只是没想到爆发的这么快。将异步写入Memcached、MySQL、Cassandra的线程分离开来，任何一个写入慢都不影响其它的写入，此问题才得以彻底解决。

另外，对需要频繁读写和计算的velocity数据，加大了缓存的使用，从最初5个小时的过期时间，改成24小时，一直到7天，提升了缓存的命中率，从目前缓存的使用率来看，还可以进一步加大缓存的过期时间，尽可能减少对Mysql和Cassandra的直接操作。

MySQL原来也是一大瓶颈，我们应用特点是大量的随机读写，但当初对MySQL的使用没有什么经验，不但使用了SAS盘，为了节省空间还用了Raid5，更进一步的是使用了5.1的版本和默认的配置，没有做任何优化，几个原因叠加在一起可想而知数据库读写性能有多差了。在专家的建议下，采购了SSD盘的新服务器，使用了5.6版本的MySQL，并对配置做了大量优化，性能有了十倍以上的提升，MySQL这个心头大患终于除掉了。

## 监控

其实一开始我就比较重视监控，选用了Zabbix来做各种监控，经过几个月的实践发现Zabbix确实不错，包括对系统CPU、内存、硬盘、IO等硬件系统的监控、应用的监控、日志的监控、Memcached插件的支持、MySQL插件的支持都不错，但还没有把业务监控完善进来，这也留下一个严重的漏洞，被我一个不小心的操作所触发，导致一个晚上的请求都被拒掉。当时Admin系统有点问题，我就帮同事定位原因，执行命令从Nginx把Admin的一台机器从负载匀衡中切掉，命令是从原来api那里copy过来的，没注意应用名没有修改掉，结果执行命令后整个Api集群被切掉，所以的请求到Nginx后就被拒绝了，出现了严重的故障。这个问题也是发生在准备增加360云监控从外部监控系统执行情况的当天晚上，原计划第二天增加结果晚上就出问题了，所以一但发现漏洞和风险，需要尽快的修复，问题总是比你想象的要来的快。

增加了外部监控后，可以监控我们所有的对外接口的响应时间以及DNS情况，一但发生类似的问题，我们可以通过监控第一时间知道并做出相应的反应，避免出现类似的严重问题。

## 总结

经过上述多个点的优化改进，系统的扩展性、高可用性、性能等都有了极大的提升，从最近一周的运行来看稳定了很多，还有更多小的优化在进行中，相信这些改进完成后，达到三季度支撑一千万/天调用量的目标应该不成问题。

从头搭建一个可扩展、高可用、性能好的高并发网站并不是一件容易的事，缺少了像大公司很多基础服务的支撑，一切从头开始会遇到各种各样的坑，不过还好我们主要是做Saas服务，发现问题可以快速改进，还有挽回的机会，但希望不要是跌进去就爬不出来的坑，这需要技术团队在系统架构、性能优化、代码开发、系统运维等各个方面都要快速学习积累经验应对业务的各种挑战，是压力也是动力，加油！


